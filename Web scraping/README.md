# Web Scarping of the nikola tesla 

1.Scraping: Scraping refers to the process of extracting data from websites. This could involve pulling
information from web pages, APIs, or any other online source. Web scraping can be done manually,
but it's often automated using software tools known as web scrapers or crawlers. Scraping can involve
extracting text, images, links, or any other content available onthe web.

2.Crawling: Crawling is the process of systematically browsing the internet to discover and index web
pages. Search engines like Google use crawlers (also known as spiders or bots) to traverse the web,
following links from one page to another and gathering information about eachpage they visit. Crawling
is a crucial step in indexing web content, enabling search engines to provide relevant results to users.

3.Parsing: Parsing involves breaking down a piece of data into its component parts and interpreting its
structure. In the context of web scraping, parsing is often used to extract specificinformation from HTML
or other markup languages. For example, a parser might extract the text of a particular HTML element,
extract attributes from tags, or identify patterns within the text.
Parsing is essential for extracting meaningful data from raw web pages during the scraping process.

Firstly, install the Selenium
pip install selenium

Secondly, install the beautifulsoup4
pip install requests beautifulsoup4

Thirdly, install the boilerpipe3
!pip install boilerpipe3

Fourth, install the feedparser
!pip install feedparser

References:
https://medium.com/analytics-vidhya/web-scraping-with-python-beginner-to-advanced-10daaca021f3

https://www.zenrows.com/blog/web-crawler-python#extract-data-into-csv
